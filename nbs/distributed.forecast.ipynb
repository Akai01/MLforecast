{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f1aea-1fd9-4818-8fe8-cd8655813129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp distributed.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7d947-ce42-40ec-8b54-623ec2189dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82054e-db3d-43ca-a4fe-c397e351ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898fb6b-131b-4895-bb0e-5c763a9325af",
   "metadata": {},
   "source": [
    "# Distributed Forecast\n",
    "\n",
    "> Distributed pipeline encapsulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e3690-1951-487a-8c66-ba1b2cc01756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Callable, Dict, Optional\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, default_client\n",
    "\n",
    "from mlforecast.core import preprocessing_flow\n",
    "from mlforecast.distributed.core import distributed_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df7343e-661c-4805-a8c3-08117efd1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from window_ops.rolling import *\n",
    "from window_ops.expanding import *\n",
    "from window_ops.ewm import ewm_mean\n",
    "\n",
    "from mlforecast.distributed.models import LGBMForecast, XGBForecast\n",
    "from mlforecast.utils import generate_daily_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aee7c1-f3cd-4a76-bb0a-9b437da29a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DistributedForecast:\n",
    "    \n",
    "    def __init__(self, model, flow_config: Dict, client: Optional[Client] = None):\n",
    "        self.model = model\n",
    "        self.flow_config = flow_config\n",
    "        self.client = client or default_client()\n",
    "        \n",
    "    def preprocess(self, data: dd.DataFrame, prep_fn: Callable = preprocessing_flow) -> dd.DataFrame:\n",
    "        self.data_divisions = data.divisions\n",
    "        self.ts, train_ddf = distributed_preprocess(data, self.flow_config, self.client, prep_fn)\n",
    "        return train_ddf\n",
    "    \n",
    "    def fit(self, data: dd.DataFrame, **kwargs) -> 'DistributedForecast':\n",
    "        train_ddf = self.preprocess(data)\n",
    "        X, y = train_ddf.drop(columns=['ds', 'y']), train_ddf.y\n",
    "        self.model.fit(X, y, **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, horizon: int) -> dd.DataFrame:\n",
    "        return self.model.predict(self.ts, horizon, self.data_divisions)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'DistributedForecast(model={self.model}, flow_config={self.flow_config})'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b21c7-23fa-4628-be0d-4da2448fa382",
   "metadata": {},
   "source": [
    "The `DistributedForecast` class is a high level abstraction that encapsulates all the steps in the pipeline (preprocessing, fitting the model and computing predictions) and applies them in a distributed way.\n",
    "\n",
    "In order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using `dask`. The current implementations are in `LGBMForecast` and `XGBForecast` which are just wrappers around `DaskLGBMRegressor` and `DaskXGBRegressor` that add a `model_` property to get the trained model from them and send it to every worker to perform the predictions step.\n",
    "\n",
    "The different things that you need to use `DistributedForecast` (as opposed to `Forecast`) are:\n",
    "1. You need to set up a `dask.distributed.Client`. If this client is connected to a remote cluster then the process will run there.\n",
    "2. Your data needs to be a `dask.dataframe`.\n",
    "3. You need to use a model that implements distributed training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd506dab-4486-48fe-8632-e1f28716057b",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6479a531-60db-4c1e-ac28-189b8628d3ef",
   "metadata": {},
   "source": [
    "### 1. Set up a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea1b0f-f8d3-4be5-89fe-3dcbe00dff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cfccf-5898-4046-a6c8-091fec26f0e4",
   "metadata": {},
   "source": [
    "### 2. Set up your data. \n",
    "\n",
    "The data is given as a `dask.dataframe`, it is recommended that you make sure that each time serie is only in one partition and that you have as many partitions as you have workers.\n",
    "\n",
    "The required input format is the same as for `Forecast`, except that it's a `dask.dataframe` instead of a `pandas.dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388b1cf-78cb-4cf9-b146-6d2043d4d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_daily_series(100, n_static_features=2)\n",
    "partitioned_series = dd.from_pandas(series, npartitions=2)\n",
    "partitioned_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24ce39-aea9-4cd3-bffe-7ac0b53c563f",
   "metadata": {},
   "source": [
    "As in the local version (`Forecast`) a flow configuration is required. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b6281f-1e65-433b-aad2-2d9895a64bcb",
   "metadata": {},
   "source": [
    "### Flow configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b682a9-7b7a-429f-8d25-a0d0ae4aafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_config = dict(\n",
    "    freq='D',\n",
    "    lags=[7, 14],\n",
    "    lag_transforms={\n",
    "        1: [\n",
    "            expanding_mean\n",
    "        ],\n",
    "        7: [\n",
    "            (rolling_mean, 7), \n",
    "            (rolling_std, 7),\n",
    "        ]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month', 'year'],\n",
    "    num_threads=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e1983-7235-4930-9b44-36c76e35be69",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d0221-9295-4570-a687-e36087cff817",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedForecast(LGBMForecast(), flow_config)\n",
    "fcst.fit(partitioned_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961fb48-54de-48f1-a868-824bed51f596",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a439d-e0d0-4f2f-925c-fccd92361c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst.predict(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce8bf7e-b282-4da0-829a-96f029ff63d7",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8b52f-efa4-4147-8c3b-9680b08c3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_n_mask(serie, n):\n",
    "    mask = np.full_like(serie, False, dtype=bool)\n",
    "    mask[-n:] = True\n",
    "    return mask\n",
    "\n",
    "test_size = 14\n",
    "valid_mask = series.groupby('unique_id')['y'].transform(get_last_n_mask, test_size)\n",
    "train = dd.from_pandas(series[~valid_mask], npartitions=2)\n",
    "y_valid = series[valid_mask].set_index('ds', append=True)[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbbcae5-3607-4c91-af0b-ca5ed9ec23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preds(train, model, cats2int=False):\n",
    "    if cats2int:\n",
    "        train = train.copy()\n",
    "        for col in train.select_dtypes(include='category'):\n",
    "            train[col] = train[col].cat.codes\n",
    "            \n",
    "    fcst = DistributedForecast(model, flow_config)\n",
    "    fcst.fit(train)\n",
    "    preds = fcst.predict(test_size).compute()\n",
    "\n",
    "    evals = y_valid.join(preds.set_index('ds', append=True))\n",
    "    evals['sq_err'] = (evals['y'] - evals['y_pred'])**2\n",
    "    mse = evals.groupby('unique_id')['sq_err'].mean().mean()\n",
    "    print(f'MSE: {mse:.1f}')\n",
    "    \n",
    "    valid_sum = y_valid.groupby('ds').sum()\n",
    "    preds_sum = preds.groupby('ds')['y_pred'].sum()\n",
    "    valid_sum.join(preds_sum).plot(marker='.', figsize=(16, 6)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae598a8-d6dc-4cec-94de-5c7ea1987b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_preds(train, LGBMForecast())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a5253-2916-4363-b933-154000a65dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_preds(train, XGBForecast(), cats2int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e1bf7-2096-41b2-9298-d1cdc94c2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
